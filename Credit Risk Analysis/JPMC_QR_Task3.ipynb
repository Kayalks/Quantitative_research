{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "import base64\n",
        "import requests\n",
        "import json\n",
        "\n"
      ],
      "metadata": {
        "id": "QXC-7Gmwyy8b"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the Data"
      ],
      "metadata": {
        "id": "46DWLfGDiYq1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "wLL_Mem4iXVH"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Replace with your GitHub details\n",
        "github_token = \"your token\"\n",
        "repo_owner = \"your username\"\n",
        "repo_name = \"your repo name\"\n",
        "file_path = \"data/Task 3 and 4_Loan_Data.csv\"\n",
        "\n",
        "# GitHub API URL\n",
        "github_api_url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}/contents/{file_path}\"\n",
        "\n",
        "# Request the file with authentication\n",
        "headers = {\"Authorization\": f\"token {github_token}\"}\n",
        "response = requests.get(github_api_url, headers=headers)\n",
        "\n",
        "if response.status_code == 200:\n",
        "    file_info = response.json()\n",
        "    file_download_url = file_info['download_url']\n",
        "\n",
        "    # Load the CSV file\n",
        "    df = pd.read_csv(file_download_url)\n",
        "\n",
        "else:\n",
        "    print(f\"❌ Error: Unable to fetch file. Status Code: {response.status_code}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train the Machine Learning Model\n",
        "We train the XGBoost model on the dataset and implement functions for:\n",
        "\n",
        "- Probability of Default (PD)\n",
        "- Expected Loss (EL)"
      ],
      "metadata": {
        "id": "drF5OdJq9zyc"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "62O8iZSI9nmF",
        "outputId": "17df5221-b2d7-41a2-977c-50554a72e76a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/xgboost/core.py:158: UserWarning: [22:58:01] WARNING: /workspace/src/learner.cc:740: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  warnings.warn(smsg, UserWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ XGBoost Model Successfully Trained!\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# ✅ Preprocess Data\n",
        "df['DTI_ratio'] = df['total_debt_outstanding'] / df['income']  # Debt-to-Income Ratio\n",
        "df.drop(columns=['customer_id'], inplace=True)  # Drop customer_id\n",
        "\n",
        "# Define Features (X) and Target (y)\n",
        "X = df.drop(columns=['default'])\n",
        "y = df['default']\n",
        "\n",
        "# Train-Test Split (80-20)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Scale Numerical Features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# ✅ Train XGBoost Model\n",
        "best_model = XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\")\n",
        "best_model.fit(X_train_scaled, y_train)\n",
        "\n",
        "print(\"✅ XGBoost Model Successfully Trained!\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Implement Probability of Default (PD) & Expected Loss (EL) Functions"
      ],
      "metadata": {
        "id": "QzfzOvCp-Cak"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict_pd(credit_lines, loan_amt, total_debt, income, years_employed, fico_score):\n",
        "    \"\"\"\n",
        "    Function to predict Probability of Default (PD).\n",
        "    \"\"\"\n",
        "    dti_ratio = total_debt / income  # Debt-to-Income Ratio\n",
        "\n",
        "    # Create input feature array\n",
        "    customer_features = np.array([[credit_lines, loan_amt, total_debt, income, years_employed, fico_score, dti_ratio]])\n",
        "\n",
        "    # Scale input features\n",
        "    customer_features_scaled = scaler.transform(customer_features)\n",
        "\n",
        "    # Predict Probability of Default\n",
        "    pd_value = best_model.predict_proba(customer_features_scaled)[:, 1][0]\n",
        "\n",
        "    return pd_value\n",
        "\n",
        "def expected_loss(credit_lines, loan_amt, total_debt, income, years_employed, fico_score):\n",
        "    \"\"\"\n",
        "    Function to compute Expected Loss (EL) in GBP.\n",
        "    \"\"\"\n",
        "    recovery_rate = 0.10  # 10% Recovery Rate\n",
        "    pd_value = predict_pd(credit_lines, loan_amt, total_debt, income, years_employed, fico_score)\n",
        "    el_value = pd_value * loan_amt * (1 - recovery_rate)\n",
        "\n",
        "    return el_value\n"
      ],
      "metadata": {
        "id": "3np89w-0-Equ"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generate Predictions & Save to GitHub\n",
        "We will:\n",
        "\n",
        "1. Apply the model to the test set to generate PD & EL.\n",
        "2. Save results to CSV.\n",
        "3. Upload processed file back to GitHub."
      ],
      "metadata": {
        "id": "uZ3soTLr-ITm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ✅ Apply Model to Test Data\n",
        "test_results = X_test.copy()\n",
        "test_results['PD'] = best_model.predict_proba(X_test_scaled)[:, 1]  # Probability of Default\n",
        "test_results['EL'] = test_results['loan_amt_outstanding'] * test_results['PD'] * (1 - 0.10)  # Expected Loss (10% Recovery)\n",
        "\n",
        "# ✅ Save Processed Data\n",
        "output_filename = \"loan_predictions.csv\"\n",
        "test_results.to_csv(output_filename, index=False)\n",
        "print(f\"✅ Predictions saved to {output_filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bpQP7zt-HuQ",
        "outputId": "9c4a03c2-2e06-4246-fbba-50e1508e36dc"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Predictions saved to loan_predictions.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Upload Predictions to GitHub"
      ],
      "metadata": {
        "id": "N-hN4GJu-R02"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import json\n",
        "\n",
        "# ✅ Define upload details\n",
        "upload_url = f\"https://api.github.com/repos/{repo_owner}/{repo_name}/contents/data/{output_filename}\"\n",
        "\n",
        "def upload_to_github(file_path, upload_url):\n",
        "    with open(file_path, \"rb\") as file:\n",
        "        content = file.read()\n",
        "        encoded_content = base64.b64encode(content).decode(\"utf-8\")  # Proper Base64 encoding\n",
        "\n",
        "    # Check if file exists to get `sha`\n",
        "    response = requests.get(upload_url, headers={\"Authorization\": f\"Bearer {github_token}\"})\n",
        "    sha = response.json().get(\"sha\", None) if response.status_code == 200 else None\n",
        "\n",
        "    # ✅ Construct the payload\n",
        "    payload = {\n",
        "        \"message\": f\"Updating {file_path}\",\n",
        "        \"content\": encoded_content,\n",
        "        \"branch\": \"main\"\n",
        "    }\n",
        "\n",
        "    if sha:\n",
        "        payload[\"sha\"] = sha  # Required for updating existing file\n",
        "\n",
        "    # ✅ Upload file\n",
        "    response = requests.put(upload_url, headers={\"Authorization\": f\"Bearer {github_token}\"}, json=payload)\n",
        "\n",
        "    if response.status_code in [200, 201]:\n",
        "        print(f\"✅ Successfully uploaded {file_path} to GitHub.\")\n",
        "    else:\n",
        "        print(f\"❌ Failed to upload {file_path}. Error: {response.text}\")\n",
        "\n",
        "# ✅ Upload predictions\n",
        "upload_to_github(output_filename, upload_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fzcBRg8o-U38",
        "outputId": "a88e25a9-f5fd-47b5-8f9c-c72e580a051f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Successfully uploaded loan_predictions.csv to GitHub.\n"
          ]
        }
      ]
    }
  ]
}